{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_tokenize\n",
    "разобрали текст по кусочкам\n",
    "\n",
    "в нлтк есть разбор по частям речи\n",
    "tagger = nltk.pos_tag()\n",
    "передаём ему список слов\n",
    "pos_tag возвращет кортеж со словами и частями речи\n",
    "насчитывает порядка сорока элементов\n",
    "как посмотреть часть речи слова get?\n",
    "tagged[3][1]\n",
    "\n",
    "лемматизация - приведение слова к начальной форме\n",
    "стемминг - выделение основы слова\n",
    "слово play - нач форма play, основа plai\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "    по очереди будем определять начальную форму для каждого слова\n",
    "    lemmatized = [lemm.lemmatize(word) for word in tokenized] \n",
    "wordnetlemmatizer ищет нормальную форму в словаре wordnet\n",
    "\n",
    "лемматайзер может определять нормальную форму слова с учётом части речи\n",
    "крутой подход, кроме одного \"но\"\n",
    "из-за словаря wordnet по-другому обозначаются части речи\n",
    "нет вариаций глаголов, прилагательных, существительных\n",
    "\n",
    "нужно изменить кодировку для частей речи\n",
    "сделали отдельной f pos_tager\n",
    "\n",
    "задать части речи и проблематизировать с их учётом\n",
    "tagged = [(word, pos_tagger(tag)) for word, tag in tagged]\n",
    "для всех частей речи, которые не прописаны в словаре ставим none\n",
    "потом выполняем лемматизацию\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer (language = \"english\")\n",
    "норм работает с английским, но с русским не оч\n",
    "\n",
    "лучше использовать pymorphy2\n",
    ".parse() будет давать значения слов\n",
    "scoring - даёт вероятность, существительное там это или что-то другое"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
