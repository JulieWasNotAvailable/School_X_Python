{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement torchvision.transform (from versions: none)\n",
            "ERROR: No matching distribution found for torchvision.transform\n"
          ]
        }
      ],
      "source": [
        "%pip install torchvision.transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
            "ERROR: No matching distribution found for cv2\n"
          ]
        }
      ],
      "source": [
        "%pip install cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c965f60a-bf14-4677-bc29-4cbc83347d85",
      "metadata": {
        "id": "c965f60a-bf14-4677-bc29-4cbc83347d85"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "_WrWB4tw7eeu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_WrWB4tw7eeu",
        "outputId": "99ad79c6-694c-4577-ce83-b5fc85bbe9c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(278, 278, 3)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "image = cv2.imread(\"Latin/A/5a0d5cfd92c94.png\")\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Xb8gA83K7L9W",
      "metadata": {
        "id": "Xb8gA83K7L9W"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 278, 278])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision.io import read_image\n",
        "\n",
        "image = read_image(\"Latin/A/5a0d5cfd92c94.png\")\n",
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "blFfmqHRBVCx",
      "metadata": {
        "id": "blFfmqHRBVCx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.rand(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d7d73e4f-01dc-49d3-a862-ac8dd17cdc01",
      "metadata": {
        "id": "d7d73e4f-01dc-49d3-a862-ac8dd17cdc01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToPILImage()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f_t = transforms.Lambda(lambda x: x * 2)\n",
        "f_t(a)\n",
        "transforms.ToPILImage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "49e04f39-efae-4176-b652-7e676f3d1e04",
      "metadata": {
        "id": "49e04f39-efae-4176-b652-7e676f3d1e04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToPILImage(mode=tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f_t1 = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((124, 124)),\n",
        "    transforms.PILToTensor()\n",
        "])\n",
        "f_t1(image)\n",
        "transforms.ToPILImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "rqI_eMY1D--A",
      "metadata": {
        "id": "rqI_eMY1D--A"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "h5RsaNrQEZo5",
      "metadata": {
        "id": "h5RsaNrQEZo5"
      },
      "outputs": [],
      "source": [
        "class LatinDataset(Dataset):\n",
        "  def __init__(self, path_dataset: pathlib.Path):\n",
        "    self.path_dataset = path_dataset\n",
        "    self.data_list = [x for x in self.path_dataset.glob(\"**/*\") if x.is_file()]\n",
        "    self.data_class = list(set(x.parent for x in self.data_list))\n",
        "    self.transform_func = transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.Grayscale(),\n",
        "      transforms.Resize((124, 124)),\n",
        "      transforms.PILToTensor()\n",
        "  ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = self.data_list[index]\n",
        "    img_label = torch.zeros(len(self.data_class))\n",
        "    img_label[self.data_class.index(img_path.parent)] = 1.0\n",
        "    img_tensor = read_image(img_path)\n",
        "    return self.transform_func(img_tensor), img_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2PluKkTAGOEp",
      "metadata": {
        "id": "2PluKkTAGOEp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "sji1clek8mLt",
      "metadata": {
        "id": "sji1clek8mLt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 1, 28])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.rand((2, 1, 1, 28))\n",
        "a.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "GXNd6RtyFyza",
      "metadata": {
        "id": "GXNd6RtyFyza"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 28])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.view(-1, 28).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "hjRTX9Uf3bfv",
      "metadata": {
        "id": "hjRTX9Uf3bfv"
      },
      "outputs": [],
      "source": [
        "class CVModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    self.conv_1 = nn.Conv2d(1, 32, (3, 3))\n",
        "    self.conv_2 = nn.Conv2d(32, 64, (3, 3))\n",
        "    self.pool_1 = nn.MaxPool2d((2, 2))\n",
        "    self.conv_3 = nn.Conv2d(64, 128, (3, 3))\n",
        "    self.conv_4 = nn.Conv2d(128, 128, (3, 3))\n",
        "    self.pool_2 = nn.MaxPool2d((2, 2))\n",
        "    self.glob_pool = nn.MaxPool2d((28, 28))\n",
        "    self.linear = nn.Linear(128, 26)\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, X):\n",
        "    res = self.conv_1(X)\n",
        "    res = self.conv_2(res)\n",
        "    res = self.pool_1(res)\n",
        "    res = self.conv_3(res)\n",
        "    res = self.conv_4(res)\n",
        "    res = self.pool_2(res)\n",
        "    res = self.glob_pool(res)\n",
        "    res = self.linear(res.view(-1, 128))\n",
        "    return self.softmax(res)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
