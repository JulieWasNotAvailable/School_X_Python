{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytorch\n",
    "%pip install torchvision.transform\n",
    "\n",
    "import torchvision.transforms\n",
    "# под капотом испопльзует pillow\n",
    "from torchvision.transforms import transfroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'transfroms' from 'torchvision.transforms' (c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W2sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W2sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m \u001b[39m# под капотом испопльзует pillow\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W2sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m transfroms\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'transfroms' from 'torchvision.transforms' (c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\__init__.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# opencv помогает открыть изображение, как вектор\n",
    "# менять цветовые гаммы, накладывать фильтры, делать математические операции\n",
    "# открывает картинки в формате pgr\n",
    "\n",
    "image = cv2.imread(\"\") # adress\n",
    "image.shape\n",
    "# 278 278 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(5)\n",
    "torch.size([4,278,278])\n",
    "\n",
    "\n",
    "image = read_image()\n",
    "torch_size([4,278,278])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t = transfroms.Lambda(lambda x: x*2)\n",
    "f_t(a)\n",
    "transfroms\n",
    "# PILtoTensor - изменить pillow на тензор\n",
    "# трансформ работает с пиллоу\n",
    "# сделала торч ридимэдж, теперь перееводит в объект пиллоу\n",
    "# и потом уже с ним можно будет использовать изменнеие рзамерности поалитры, гауссонблюр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose - объединяем функции в последовательность задач \n",
    "\n",
    "f_t1 = transforms.Compose([\n",
    "    transfroms.CenterCrop(), #сократить в размере\n",
    "    transforms.Resize((124, 124)), #поменять размер\n",
    "    transfroms.PilToTensor() #превратить в тензон\n",
    "])\n",
    "#возникает диллема, что мало данных, но обучить что-то хочется\n",
    "#первый подход - показывать одно и то же изображение, но с шумами, переворачиванием и тд\n",
    "#но это не поможет, если сет критически мал\n",
    "\n",
    "#второй способ - взять натренированную модель\n",
    "#VGG ResNet обучены на большом количестве данных и имеют большую точность\n",
    "#у них хорошие низкоуровневые паттерны\n",
    "#значит мы можем взять претренированные слои\n",
    "\n",
    "#эти слои мы забираем, и пишем свою  (убираем верхние слои и пишем свои) надстройку,\n",
    "# чтобы искать объекты, которые нас интерисуют"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset класс - как и откуда возвращать один объект\n",
    "#dataloader - в каком количестве групипровать, и непосредственно группировка\n",
    "#написали класс для работы с нашим датасетом\n",
    "\n",
    "class LatinDataset(Dataset):\n",
    "    def __init__(self, path_dataset: pathlib.Path):\n",
    "        self.path_dataset = path_dataset\n",
    "        self.data_list = [x for x in self.path_dataset.glob(\"**/*\") if x.is_file()] #объявили список файлов\n",
    "        #паттерн, по которому мы проходимся, папка внутри, и неважно, что после неё **/* неважно что перед, и после\n",
    "        #глоб - перечисление файлов\n",
    "        \n",
    "        self.data_class = list(set(x.parent for x in self.data_list)) #выделили количетсво классов\n",
    "        self.transform_func = transforms.Compose([\n",
    "            transforms.CenterCrop(), #сократить в размере\n",
    "            transforms.Grayscale(), #без цвета\n",
    "            transforms.Resize((124, 124)), #поменять размер\n",
    "            transfroms.PilToTensor() #превратить в тензон\n",
    "            ])\n",
    "            \n",
    "        #начинаем работать не в юпитере, а скриптами\n",
    "        #передали все данные, с которыми потом будем работать\n",
    "        #должен быть у них свой путь, мы его в ините объяснили\n",
    "        #потом выделили количество классов\n",
    "\n",
    "    def __len__(self): #длина итерируемого объекта, дать возможность датасету максимальное количество объектов, чтобы он не просил больше, чем етсь\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.data_list[index]\n",
    "        # свер\n",
    "        #2 папки 2 класса, нам нужно за лейбл \n",
    "        img_label = torch.zeros(len(self.data_class)) #zeros тензор с нулевыми значениями\n",
    "        img_label[self.data_class.index(img_path.parent)] = 1.0\n",
    "        #первая ячейка - индекс папки, это класс. \n",
    "        img_tensor = read_image(img_path).label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "операции свёртки плевать, какого размера изображение\n",
    "но батч не может заполниться разноразмерными картинками\n",
    "нужен некий resize, привести картинки к одной размерности\n",
    "\n",
    "что нужно знать - когда берём градиент фукнции, берём по значению, которое было уже расчитано\n",
    "модель запоминает прямой проход по функции\n",
    "когда картинка проходит через каждый свёрточный слой, промежуточное значение картинок остаётся в памяти\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = pathlib.Path(\"\") #adress\n",
    "a = [x for x in path_dataset.glob(\"**/*\") if x.is_file()]\n",
    "set([x.parent for x in a])\n",
    "\n",
    "\n",
    "# каждый элемент множества всегда будет уникальный \n",
    "\n",
    "#прописать сразу классы, но хочет это автоматизировать, чтобы сам класс мог определять количество классов и как их возвращать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
