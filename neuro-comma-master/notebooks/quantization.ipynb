{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CommitOperationAdd' from 'huggingface_hub' (c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RepunctPredictor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CorrectionModel\n",
      "File \u001b[1;32mc:\\Users\\1\\PycharmProjects\\i_love_tuesdays\\neuro-comma-master\\src\\neuro_comma\\predict.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizerFast\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CorrectionModel\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PRETRAINED_MODELS\n",
      "File \u001b[1;32mc:\\Users\\1\\PycharmProjects\\i_love_tuesdays\\neuro-comma-master\\src\\neuro_comma\\dataset.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizer\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUGMENTATIONS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOKEN_IDX\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseDataset\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\1\\PycharmProjects\\i_love_tuesdays\\neuro-comma-master\\src\\neuro_comma\\augmentation.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Source: https://github.com/xashru/punctuation-restoration/blob/master/src/augmentation.py\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuro_comma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrained\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOKEN_IDX\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# probability of applying substitution operation on tokens selected for augmentation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m alpha_sub \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.40\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\1\\PycharmProjects\\i_love_tuesdays\\neuro-comma-master\\src\\neuro_comma\\pretrained.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: rework with tokenizer special tags\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (AlbertModel, AlbertTokenizer, AutoModel,\n\u001b[0;32m      3\u001b[0m                           AutoTokenizer, BertModel, BertTokenizer,\n\u001b[0;32m      4\u001b[0m                           DistilBertModel, DistilBertTokenizer, RobertaModel,\n\u001b[0;32m      5\u001b[0m                           RobertaTokenizer, XLMModel, XLMRobertaModel,\n\u001b[0;32m      6\u001b[0m                           XLMRobertaTokenizer, XLMTokenizer)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# special tokens indices in different models available in transformers\u001b[39;00m\n\u001b[0;32m      9\u001b[0m TOKEN_IDX \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTART_SEQ\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     },\n\u001b[0;32m     34\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\__init__.py:2941\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __version__\n\u001b[1;32m-> 2941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\file_utils.py:1890\u001b[0m, in \u001b[0;36m_BaseLazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1889\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1890\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\file_utils.py:1889\u001b[0m, in \u001b[0;36m_BaseLazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1887\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1889\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\__init__.py:210\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:223\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpegasus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_pegasus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PegasusForCausalLM, PegasusForConditionalGeneration, PegasusModel\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprophetnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_prophetnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProphetNetForCausalLM, ProphetNetForConditionalGeneration, ProphetNetModel\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_rag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 - need to import all RagModels to be in globals() function\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     RagModel,\n\u001b[0;32m    225\u001b[0m     RagSequenceForGeneration,\n\u001b[0;32m    226\u001b[0m     RagTokenForGeneration,\n\u001b[0;32m    227\u001b[0m )\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_reformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    229\u001b[0m     ReformerForMaskedLM,\n\u001b[0;32m    230\u001b[0m     ReformerForQuestionAnswering,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     ReformerModelWithLMHead,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretribert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_retribert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetriBertModel\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\rag\\modeling_rag.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_rag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RagConfig\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrieval_rag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RagRetriever\n\u001b[0;32m     33\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     35\u001b[0m _CONFIG_FOR_DOC \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRagConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\rag\\retrieval_rag.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_rag\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RagTokenizer\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available():\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, load_dataset, load_from_disk\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_faiss_available():\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,g-bad-import-order,wrong-import-position\u001b[39;00m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.15.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\arrow_dataset.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommitOperationAdd, CommitOperationDelete, DatasetCard, DatasetCardData, HfApi\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CommitOperationAdd' from 'huggingface_hub' (c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from neuro_comma.predict import RepunctPredictor\n",
    "from neuro_comma.model import CorrectionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CorrectionModel(\n",
    "    pretrained_model=\"DeepPavlov/rubert-base-cased-sentence\",\n",
    "    targets={\n",
    "        \"O\": 0,\n",
    "        \"COMMA\": 1,\n",
    "        \"PERIOD\": 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('../models/repunct-model-new/weights/weights_ep6_9912.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = model.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.save('../models/repunct-model-new/weights/quantized_weights_ep6_9912.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:355: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    }
   ],
   "source": [
    "predictor = RepunctPredictor(model_name='repunct-model-new',\n",
    "                             models_root=Path('../models'),\n",
    "                             model_weights='quantized_weights_ep6_9912.pt',\n",
    "                             quantization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mя люблю разную еду борщи плов шаурму пастилу.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m        Я считаю что поедание борща плова и пастилы это самое лучшее что может произойти в жизни любого человека\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpredictor\u001b[49m(text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "text = (\"я люблю разную еду борщи плов шаурму пастилу.\\\n",
    "        Я считаю что поедание борща плова и пастилы это самое лучшее что может произойти в жизни любого человека\")\n",
    "\n",
    "predictor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f6647ac222ee8180da4b9f4daf24da456a5df3bc659c190f01c4ac62564739c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
